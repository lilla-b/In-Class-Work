{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff780d63",
   "metadata": {},
   "source": [
    "# Week 13 Group Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa480d6",
   "metadata": {},
   "source": [
    "## 1. In markdown, describe kNN in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a59f2f",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors, or k-NN, is a nonparametric algorithm that can be used for classification and regression problems. The k-NN method assumes that the distance between points is a measure of similarity. When we use in in a classifier context, the k-NN algorithm calculates the distances between a test observation, x, and all of the training data, to find the set of k values closest to x. Then, those k values are used to create a prediction for x. \n",
    "\n",
    "The standard distance metric is Euclidean but other metrics can be used, depending on the application (e.g. cosine similarity, chi-squared - especially good for classifying based on textures or shapes). \n",
    "\n",
    "The most commonly used statistic for k-NN model performance is the average accuracy (the fraction of correctly classified observations). Model performance can be heavily influenced by k, the number of neighbors. When k is too low, the model is underfit; it has low bias but high variance. When k is too high, the model is overfit, it has high bias and low variance. The goal is to find the value of k that balances the performance, bias, and variance. \n",
    "\n",
    "Computation time increases as the size of the data set increases. In some contexts, this can be a drawback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b36f7",
   "metadata": {},
   "source": [
    "## 2. Using the kNN example from class, write a function that finds the optimal value for k. You should iteraate over a range of values and return the k and the score when the accuracy score is maximized. Be sure to only use odd values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73a2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203a2913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436a2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Creating the feature matrix, X, and splitting out the response vector, y.  \n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "#Split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=42)\n",
    "\n",
    "#Standardization - transforming all data so that mean is zero and SD is 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "#Specifying the model, and k, the number of neighbors\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_predicted = knn.predict(X_test)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f185a5",
   "metadata": {},
   "source": [
    "#### Some scratchwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168eee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could compute the scores of the classifier for a range of values of k, and then see if we can find a maximum. This is a kind of \"naive\" approach\n",
    "\n",
    "klist=[]\n",
    "for i in range (1,100):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        klist.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2d42c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6770833333333334, 0.6848958333333334, 0.71875, 0.6822916666666666, 0.703125, 0.703125, 0.7109375, 0.7083333333333334, 0.7109375, 0.7161458333333334, 0.734375, 0.7239583333333334, 0.7317708333333334, 0.7291666666666666, 0.734375, 0.7317708333333334, 0.7473958333333334, 0.7395833333333334, 0.7421875, 0.7526041666666666, 0.75, 0.7552083333333334, 0.7369791666666666, 0.7291666666666666, 0.734375, 0.7291666666666666, 0.7317708333333334, 0.734375, 0.7213541666666666, 0.7265625, 0.71875, 0.7265625, 0.7265625, 0.7317708333333334, 0.7369791666666666, 0.7317708333333334, 0.7421875, 0.7369791666666666, 0.7447916666666666, 0.7526041666666666, 0.7447916666666666, 0.7526041666666666, 0.7473958333333334, 0.7447916666666666, 0.7526041666666666, 0.7578125, 0.7552083333333334, 0.7578125, 0.7552083333333334, 0.75, 0.7552083333333334, 0.75, 0.7604166666666666, 0.7526041666666666, 0.7604166666666666, 0.7473958333333334, 0.7552083333333334, 0.7473958333333334, 0.7552083333333334, 0.75, 0.7578125, 0.7526041666666666, 0.7578125, 0.7552083333333334, 0.7604166666666666, 0.75, 0.765625, 0.7630208333333334, 0.7630208333333334, 0.7578125, 0.7578125, 0.75, 0.7552083333333334, 0.7473958333333334, 0.7552083333333334, 0.7447916666666666, 0.75, 0.734375, 0.7369791666666666, 0.734375, 0.734375, 0.7395833333333334, 0.7421875, 0.7421875, 0.7421875, 0.7395833333333334, 0.7447916666666666, 0.7317708333333334, 0.7395833333333334, 0.734375, 0.734375, 0.734375, 0.7369791666666666, 0.7291666666666666, 0.7291666666666666, 0.7265625, 0.7291666666666666, 0.7291666666666666, 0.7317708333333334]\n"
     ]
    }
   ],
   "source": [
    "#Let's check it out:\n",
    "print(klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d82a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a list, so we can find the maximum value in the list and get it's index position.\n",
    "\n",
    "#max value\n",
    "max(klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5824f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index position\n",
    "np.argmax(klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3465b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since indexing starts with 0, the actual k = index + 1 = 67."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d7fa4",
   "metadata": {},
   "source": [
    "#### Function for tuning k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1078cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_tune ():\n",
    "    knn_list=[]\n",
    "    for i in range(1,100):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_predicted = knn.predict(X_test)\n",
    "        knn_list.append(knn.score(X_test,y_test))\n",
    "    return knn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aed05915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k is: 67 with an accuracy score of: 0.765625\n"
     ]
    }
   ],
   "source": [
    "#As above, to find the optimal k, find the index of the highest score in the list, and add 1\n",
    "\n",
    "opt_k=np.argmax(knn_tune())+1\n",
    "\n",
    "opt_score=max(knn_tune())\n",
    "\n",
    "print('The optimal k is: ' + str(opt_k) + ' with an accuracy score of: ' + str(opt_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401cc63",
   "metadata": {},
   "source": [
    "## 3. How did the panel influence your thoughts about working in tech, specifically work in the data realm? Discuss with your group and summarize your thoughts in under 250 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dbffe4",
   "metadata": {},
   "source": [
    "I enjoyed the discussion with the panel and appreciated their insights and expertise. The three main takeaways for me were: 1) you have to have solid coding foundations, 2) for long term success, you must be a lifetime learner and 3) it pays to be a good communicator.\n",
    "\n",
    "There was one question that I kept wanting to ask, but I didn't, because it's a bit of a downer question and I didn't want to introduce any fears or negative thoughts into what was an enjoyable, uplifting, and inspiring conversation. I wanted to know their thoughts on market saturation. Data science bootcamps, certificates, and even degree programs are everywhere, now, and, while data science may be a growing industry, it seems like the number of individuals who go through training programs will rapidly outpace the number of available jobs (if it hasn't already). I read one data scientists blog entry about it, from 2019, she's been in the field for over 10 years, and I keep refraining from posting it to Slack because again I don't want to generate anxiety. I do think that it is something worth considering. I spoke about it with my group for a little bit and our general conclusion was to just ignore that possibility (market saturation). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
